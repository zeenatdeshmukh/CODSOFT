# -*- coding: utf-8 -*-
"""Credit Card Fraud Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-Dx4_W1n9QR3JjHwnh3dpnMUFk8Iwn_D
"""

# Importing required libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import precision_score, recall_score, f1_score, classification_report
from imblearn.over_sampling import SMOTE
from collections import Counter

# Load the credit card dataset
file_path = 'creditcard.csv'
data = pd.read_csv(file_path)

# Data Exploration
print("Dataset shape:", data.shape)
print("First few rows of the dataset:\n", data.head())
print("Class distribution:\n", data['Class'].value_counts())

# Separate features and target
X = data.drop(columns=['Class'])
y = data['Class']

# Data Preprocessing
# Standardize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Handle class imbalance using SMOTE (Synthetic Minority Oversampling Technique)
print("Original class distribution:", Counter(y))
smote = SMOTE(random_state=42)

# Drop rows with NaN values in the target variable 'y' before applying SMOTE
X_scaled = X_scaled[~np.isnan(y)] # Drop rows in X_scaled corresponding to NaN in y
y = y.dropna() # Drop NaN values from y

X_resampled, y_resampled = smote.fit_resample(X_scaled, y)
print("Resampled class distribution:", Counter(y_resampled))

# Handle class imbalance using SMOTE (Synthetic Minority Oversampling Technique)
print("Original class distribution:", Counter(y))
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_scaled, y)
print("Resampled class distribution:", Counter(y_resampled))

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

# Model Training
# Initialize the classifier (using Random Forest here; Logistic Regression is another option)
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Model Prediction
y_pred = model.predict(X_test)

# Model Evaluation
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("Model Evaluation Metrics:")
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)
print("\nClassification Report:\n", classification_report(y_test, y_pred))